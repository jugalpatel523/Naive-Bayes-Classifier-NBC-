{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name :     Jugal Pareshbhai Patel\n",
    "# UTA ID :   1001769143\n",
    "\n",
    "\n",
    "import os \n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import numpy \n",
    "from random import seed, shuffle\n",
    "from math import log\n",
    "\n",
    "#paths = ['Downloads/aclImdb/train/neg/',  'Downloads/aclImdb/train/pos/', 'Downloads/aclImdb/test/neg/', 'Downloads/aclImdb/test/pos/']\n",
    "path_to_train_data = ['Downloads/aclImdb/train/neg/', 'Downloads/aclImdb/train/pos/' ]\n",
    "path_to_test_data = ['Downloads/aclImdb/test/neg/' ,'Downloads/aclImdb/test/pos/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    files = [path + file for file in os.listdir(path)]\n",
    "    \n",
    "    temp_data = []\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding = 'utf-8') as f:\n",
    "            #for line in f.readlines():\n",
    "            #    temp_data.append(line.replace('<br />', '').translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "            temp_data.append(f.read())\n",
    "    return temp_data\n",
    "\n",
    "def format_data(data):\n",
    "    for i, d in enumerate(data):\n",
    "        d = re.sub('[^0-9a-zA-Z]+', ' ', d.lower())\n",
    "        data[i] = ' '.join(d.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = [[], []]\n",
    "\n",
    "for path in path_to_train_data:\n",
    "    train_data_list[path_to_train_data.index(path)] = load_data(path)\n",
    "\n",
    "train_Negative_Data, train_Positive_Data = train_data_list[0], train_data_list[1]\n",
    "\n",
    "format_data(train_Negative_Data)\n",
    "format_data(train_Positive_Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = [[], []]\n",
    "\n",
    "for path in path_to_test_data:\n",
    "    test_data_list[path_to_test_data.index(path)] = load_data(path)\n",
    "\n",
    "test_Negative_Data, test_Positive_Data = test_data_list[0], test_data_list[1]\n",
    "\n",
    "format_data(test_Negative_Data)\n",
    "format_data(test_Positive_Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_Negative_Data))\n",
    "print(len(train_Positive_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Neg_Datalabel, train_Pos_Datalabel = [], []\n",
    "test_Neg_Datalabel, test_Pos_Datalabel = [], []\n",
    "\n",
    "train_Labeled_DataList = [train_Neg_Datalabel, train_Pos_Datalabel]\n",
    "test_Labeled_DataList = [test_Neg_Datalabel, test_Pos_Datalabel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_working(data, outputList):\n",
    "    for d in data:\n",
    "        for x in d:\n",
    "            outputList[data.index(d)].append([x, int(data.index(d))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Label_working(train_data_list, train_Labeled_DataList)\n",
    "Label_working(test_data_list, test_Labeled_DataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_Neg_Datalabel))\n",
    "print(len(train_Pos_Datalabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Data_labeled = train_Neg_Datalabel + train_Pos_Datalabel\n",
    "test_Data_labeled = test_Neg_Datalabel + test_Pos_Datalabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.  a. Divide the dataset as train, development and test.\n",
    "\n",
    "k = 0.75\n",
    "train_Data, dev_Data = [], []\n",
    "random.shuffle(train_Data_labeled)\n",
    "train_Data = train_Data_labeled[:int(len(train_Data_labeled)*k)]\n",
    "dev_Data = train_Data_labeled[int(len(train_Data_labeled)*k):]\n",
    "\n",
    "test_Data = test_Data_labeled\n",
    "random.shuffle(test_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train dataset :  18750\n",
      "Size of Development dataset :  6250\n",
      "Size of Test dataset :  25000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Size of Train dataset : ', len(train_Data))\n",
    "print('Size of Development dataset : ', len(dev_Data))\n",
    "print('Size of Test dataset : ', len(test_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.Build a vocabulary as list. \n",
    "\n",
    "def Vocab_buider(data):\n",
    "    vocab = {} #words have 2 counts in order neg, pos\n",
    "    \n",
    "    for d in data:\n",
    "        word_set = set()\n",
    "        word_set = word_set.union(set([q for q in re.split(r'[\\s|,|;|.|/|\\[|\\]|;|\\!|?|\\'|\\\\|\\)|\\(|\\\"|@|&|#|-|*|%|>|<|^|-]\\s*',str(d[0]).replace('<br />', '').strip()) if q]))\n",
    "        for word in word_set:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = [0, 0]\n",
    "            vocab[word][d[1]] += 1\n",
    "                \n",
    "    return vocab\n",
    "\n",
    "def verify_occur_threshold(vocab, Occurance_count):\n",
    "    for key in list(vocab.keys()):\n",
    "        if vocab[key][0] + vocab[key][1] < Occurance_count:\n",
    "            del vocab[key]\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': [372, 453],\n",
       " 'and': [8993, 9131],\n",
       " 'it': [8401, 8352],\n",
       " 'great': [1525, 3170],\n",
       " 'worry': [59, 52],\n",
       " 'enjoyable': [186, 388],\n",
       " 'either': [768, 479],\n",
       " 'christopher': [119, 136],\n",
       " 'performance': [613, 1107],\n",
       " 'family': [559, 1030],\n",
       " 'whom': [187, 256],\n",
       " 'show': [1183, 1328],\n",
       " 'you': [5294, 4969],\n",
       " 'want': [1366, 977],\n",
       " 'good': [3659, 3565],\n",
       " 'difficult': [227, 269],\n",
       " 'make': [2664, 1949],\n",
       " 'like': [4694, 4044],\n",
       " 'pleasing': [19, 32],\n",
       " 'if': [4385, 3668],\n",
       " 'cast': [1078, 1358],\n",
       " 'kid': [359, 326],\n",
       " 'lighthearted': [6, 21],\n",
       " 'bored': [276, 108],\n",
       " 'not': [5919, 5307],\n",
       " 'parent': [42, 44],\n",
       " 'bill': [145, 189],\n",
       " 'thought': [1147, 1035],\n",
       " 'kids': [498, 469],\n",
       " 'that': [7781, 7455],\n",
       " 'fits': [60, 101],\n",
       " 'without': [1017, 1095],\n",
       " 'movie': [6196, 5285],\n",
       " 'entertain': [54, 66],\n",
       " 'a': [9052, 9073],\n",
       " 'younger': [132, 209],\n",
       " 'tears': [69, 159],\n",
       " 'story': [2568, 3171],\n",
       " 'watch': [2096, 1993],\n",
       " 'would': [3356, 2773],\n",
       " 'this': [8658, 8335],\n",
       " 'from': [4291, 4481],\n",
       " 'was': [6387, 5733],\n",
       " 'nothing': [1741, 834],\n",
       " 'of': [8883, 8904],\n",
       " 'laughs': [255, 201],\n",
       " 'lloyd': [42, 44],\n",
       " 'i': [7734, 7167],\n",
       " 'lots': [256, 259],\n",
       " 'previous': [220, 223],\n",
       " 'being': [1946, 1869],\n",
       " 'line': [659, 574],\n",
       " 'the': [9292, 9294],\n",
       " 'for': [6715, 6747],\n",
       " 'movies': [2122, 1866],\n",
       " 'to': [8897, 8734],\n",
       " 'work': [1250, 1378],\n",
       " 'dead': [631, 453],\n",
       " 'at': [5024, 4650],\n",
       " 'up': [3370, 3135],\n",
       " 'wife': [504, 685],\n",
       " 'housewives': [6, 11],\n",
       " 'as': [5778, 6312],\n",
       " 'haunting': [26, 123],\n",
       " 'did': [1972, 1620],\n",
       " 'lake': [73, 61],\n",
       " 'how': [2532, 2223],\n",
       " '90': [227, 126],\n",
       " 'paul': [173, 305],\n",
       " 'on': [5976, 5821],\n",
       " 'well': [2405, 3264],\n",
       " 'minutes': [1261, 528],\n",
       " 'together': [648, 833],\n",
       " 'she': [1988, 2139],\n",
       " 'desperate': [119, 103],\n",
       " 'so': [4749, 4063],\n",
       " 'my': [2985, 3130],\n",
       " 'eva': [26, 38],\n",
       " 'enjoyed': [251, 595],\n",
       " 'looking': [907, 715],\n",
       " 'in': [8187, 8332],\n",
       " 'willing': [102, 127],\n",
       " 'expecting': [212, 204],\n",
       " 'golden': [52, 107],\n",
       " 'look': [1395, 1197],\n",
       " 'place': [731, 831],\n",
       " 'bell': [40, 32],\n",
       " 'with': [6446, 6653],\n",
       " 'they': [4498, 3736],\n",
       " 'nominated': [33, 97],\n",
       " 'very': [2799, 3678],\n",
       " 'however': [1113, 1122],\n",
       " 'match': [103, 131],\n",
       " 'girlfriend': [223, 190],\n",
       " 'reality': [240, 354],\n",
       " 'globe': [11, 36],\n",
       " 'guy': [1024, 631],\n",
       " 's': [6776, 6853],\n",
       " 'anchorman': [7, 9],\n",
       " 'wore': [37, 27],\n",
       " 'who': [4016, 4433],\n",
       " 'come': [1068, 1027],\n",
       " 'need': [625, 580],\n",
       " 'rethink': [5, 4],\n",
       " 'real': [1314, 1452],\n",
       " 'then': [2372, 1827],\n",
       " 'are': [5170, 5361],\n",
       " 'longoria': [14, 17],\n",
       " 'about': [4067, 3831],\n",
       " 'characters': [1919, 1933],\n",
       " 'time': [3236, 3338],\n",
       " 'rudd': [11, 12],\n",
       " 'new': [1048, 1355],\n",
       " 'went': [536, 450],\n",
       " 'gabrielle': [4, 5],\n",
       " 'he': [3718, 4026],\n",
       " 'is': [8311, 8538],\n",
       " 'same': [1243, 1211],\n",
       " 'friends': [510, 626],\n",
       " 'suspend': [28, 31],\n",
       " 've': [1565, 1399],\n",
       " 'all': [4910, 4916],\n",
       " 'panther': [6, 2],\n",
       " 'funny': [1222, 1118],\n",
       " 'right': [1012, 1077],\n",
       " 'sex': [561, 349],\n",
       " 'by': [4256, 4531],\n",
       " 'leads': [222, 273],\n",
       " 'picturesque': [7, 12],\n",
       " 'excellent': [268, 1061],\n",
       " 'casting': [216, 206],\n",
       " 'between': [875, 1200],\n",
       " 'ruin': [92, 67],\n",
       " 'what': [3899, 3533],\n",
       " 'feel': [875, 1037],\n",
       " 'redeemed': [15, 7],\n",
       " 'even': [3691, 2657],\n",
       " 'be': [5581, 5035],\n",
       " 'shame': [268, 182],\n",
       " 'forced': [277, 212],\n",
       " 'plants': [14, 11],\n",
       " 'also': [1962, 2875],\n",
       " 'minor': [107, 171],\n",
       " 'tone': [134, 188],\n",
       " 'through': [1586, 1460],\n",
       " 'legacy': [22, 30],\n",
       " 'highly': [197, 609],\n",
       " 'gets': [995, 977],\n",
       " 'protagonist': [83, 91],\n",
       " 'ludicrous': [104, 25],\n",
       " 'an': [4476, 4707],\n",
       " 'her': [2272, 2579],\n",
       " 'way': [2232, 2305],\n",
       " 'likeable': [25, 18],\n",
       " 'interest': [409, 320],\n",
       " 'which': [2826, 2841],\n",
       " 'turn': [493, 431],\n",
       " 'extract': [6, 9],\n",
       " 'unfortunately': [665, 299],\n",
       " 'rather': [843, 819],\n",
       " 'baron': [10, 8],\n",
       " 'particularly': [333, 394],\n",
       " 'earning': [8, 11],\n",
       " 'can': [3751, 3492],\n",
       " 'devine': [8, 0],\n",
       " 'turns': [395, 466],\n",
       " 'few': [1323, 1229],\n",
       " 'final': [393, 474],\n",
       " 'bit': [837, 1103],\n",
       " 'some': [3782, 3495],\n",
       " 'village': [75, 88],\n",
       " 'every': [1244, 1258],\n",
       " 'going': [1409, 1106],\n",
       " 'does': [1663, 1766],\n",
       " 'comedy': [779, 933],\n",
       " 'has': [3573, 3998],\n",
       " 'award': [80, 194],\n",
       " 'viewer': [369, 455],\n",
       " 'retired': [23, 36],\n",
       " 'drug': [122, 111],\n",
       " 'cannabis': [3, 2],\n",
       " 'marijuana': [9, 19],\n",
       " 'eccentric': [28, 53],\n",
       " 'descend': [5, 3],\n",
       " 'ned': [15, 45],\n",
       " 'brenda': [21, 34],\n",
       " 'transformation': [28, 41],\n",
       " 'widowed': [10, 21],\n",
       " 'greenhouse': [6, 4],\n",
       " 'dose': [26, 32],\n",
       " 'genteel': [2, 7],\n",
       " 'local': [280, 289],\n",
       " 'them': [2187, 2040],\n",
       " 'waking': [22, 15],\n",
       " 'slapstick': [56, 60],\n",
       " 'ladies': [84, 105],\n",
       " 'aged': [84, 86],\n",
       " 'lucrative': [5, 2],\n",
       " 'largely': [78, 90],\n",
       " 'debts': [4, 12],\n",
       " 'mix': [135, 138],\n",
       " 'film': [5130, 5351],\n",
       " 'revolution': [38, 61],\n",
       " 'leading': [184, 246],\n",
       " '1998': [21, 18],\n",
       " 'situation': [196, 262],\n",
       " 'saving': [123, 64],\n",
       " 'one': [5273, 5407],\n",
       " 'relationship': [196, 418],\n",
       " 'last': [892, 960],\n",
       " 'fake': [233, 84],\n",
       " 'contenders': [3, 3],\n",
       " 'will': [2111, 2636],\n",
       " 'really': [3070, 2706],\n",
       " 'money': [1057, 450],\n",
       " 'small': [447, 651],\n",
       " 'naturally': [88, 102],\n",
       " 'because': [2568, 2134],\n",
       " 'gardener': [12, 6],\n",
       " 'seven': [84, 124],\n",
       " 'whose': [268, 367],\n",
       " 'gentle': [17, 58],\n",
       " 'emotionally': [56, 114],\n",
       " 'sadly': [252, 143],\n",
       " 'confrontation': [20, 33],\n",
       " 'tricky': [9, 13],\n",
       " 'amount': [170, 172],\n",
       " 'populated': [23, 16],\n",
       " 'portrayed': [179, 236],\n",
       " 'br': [5658, 5378],\n",
       " 'ends': [349, 331],\n",
       " 'jacques': [6, 26],\n",
       " 'husband': [247, 324],\n",
       " 'simultaneously': [20, 35],\n",
       " 'involved': [369, 361],\n",
       " 'its': [1780, 2178],\n",
       " 'trying': [982, 661],\n",
       " 'themselves': [403, 425],\n",
       " 'unconventional': [12, 22],\n",
       " 'silliness': [34, 21],\n",
       " 'lord': [84, 136],\n",
       " 'fit': [159, 176],\n",
       " 'adequate': [46, 34],\n",
       " 'rapport': [3, 9],\n",
       " 'inhabitants': [16, 36],\n",
       " 'roles': [291, 465],\n",
       " 'matthew': [26, 40],\n",
       " 'police': [287, 296],\n",
       " 'middle': [363, 312],\n",
       " 'ensue': [14, 16],\n",
       " 'world': [819, 1352],\n",
       " 'surely': [154, 135],\n",
       " 'implausible': [52, 23],\n",
       " 'french': [152, 267],\n",
       " 'potential': [278, 160],\n",
       " 'certain': [229, 297],\n",
       " 'bad': [3313, 1139],\n",
       " 'totally': [487, 356],\n",
       " 'quaint': [18, 17],\n",
       " 'liberal': [42, 48],\n",
       " 'growing': [72, 143],\n",
       " 'into': [2420, 2378],\n",
       " 'humour': [105, 178],\n",
       " 'oddball': [12, 9],\n",
       " 'helped': [97, 135],\n",
       " 'blethyn': [6, 5],\n",
       " 'grace': [111, 90],\n",
       " 'character': [1776, 1824],\n",
       " 'expertise': [8, 14],\n",
       " 'romantic': [169, 351],\n",
       " 'such': [1488, 1530],\n",
       " 'recently': [164, 266],\n",
       " 'left': [750, 628],\n",
       " 'scenes': [1561, 1394],\n",
       " 'than': [2794, 2560],\n",
       " '9': [158, 355],\n",
       " 'those': [1318, 1489],\n",
       " 'extend': [9, 10],\n",
       " 'exaggerated': [49, 45],\n",
       " 'legend': [89, 102],\n",
       " 'sorry': [395, 153],\n",
       " 'yuk': [9, 4],\n",
       " 'half': [848, 468],\n",
       " 'space': [239, 191],\n",
       " 'eternity': [35, 14],\n",
       " 'sai': [2, 3],\n",
       " 'outer': [64, 22],\n",
       " 'managed': [154, 135],\n",
       " 'corey': [15, 13],\n",
       " 'plot': [2369, 1434],\n",
       " 'better': [2052, 1447],\n",
       " 'thing': [1744, 1072],\n",
       " 'specially': [21, 37],\n",
       " 'have': [5631, 5010],\n",
       " 't': [6330, 5034],\n",
       " 'yet': [758, 955],\n",
       " 'fight': [340, 354],\n",
       " 'doesn': [1538, 1194],\n",
       " 'hour': [524, 273],\n",
       " 'more': [3277, 3521],\n",
       " 'yuen': [2, 10],\n",
       " 'stuff': [447, 349],\n",
       " 'fong': [1, 5],\n",
       " 'jet': [30, 35],\n",
       " 'enough': [1257, 888],\n",
       " 'but': [6887, 6547],\n",
       " 'pretty': [1251, 934],\n",
       " 'man': [1331, 1688],\n",
       " 'much': [2793, 2568],\n",
       " 'li': [27, 29],\n",
       " 'plan': [160, 127],\n",
       " 'flick': [512, 309],\n",
       " 'badly': [374, 68],\n",
       " '360': [10, 6],\n",
       " 'expectations': [155, 120],\n",
       " 'baptism': [3, 3],\n",
       " 'coffee': [44, 33],\n",
       " 'here': [1725, 1533],\n",
       " 'quintessential': [4, 26],\n",
       " 'tumbling': [4, 6],\n",
       " 'back': [1452, 1514],\n",
       " 'antics': [38, 46],\n",
       " 'delia': [7, 0],\n",
       " 'hippie': [31, 23],\n",
       " 'turning': [150, 105],\n",
       " 'seemed': [556, 327],\n",
       " 'non': [373, 266],\n",
       " 'runs': [178, 187],\n",
       " 'church': [116, 101],\n",
       " 'mother': [328, 459],\n",
       " 'worthy': [141, 118],\n",
       " 'allows': [51, 132],\n",
       " 're': [1458, 1147],\n",
       " 'something': [1764, 1302],\n",
       " 'making': [1084, 811],\n",
       " 'considered': [151, 190],\n",
       " 'onset': [5, 5],\n",
       " 'little': [1716, 1865],\n",
       " 'script': [1258, 604],\n",
       " 'scratches': [5, 5],\n",
       " 'glances': [10, 10],\n",
       " 'unrealistic': [115, 37],\n",
       " 'personally': [134, 182],\n",
       " 'horror': [984, 580],\n",
       " 'numerous': [101, 101],\n",
       " 'times': [908, 1196],\n",
       " 'gone': [265, 265],\n",
       " 'act': [467, 334],\n",
       " 'relying': [14, 23],\n",
       " 'baby': [188, 209],\n",
       " 'mysticism': [8, 9],\n",
       " 'later': [579, 830],\n",
       " 'death': [557, 596],\n",
       " 'horrified': [23, 14],\n",
       " 'shot': [682, 614],\n",
       " 'apparently': [414, 214],\n",
       " 'around': [1179, 1050],\n",
       " 'or': [4291, 3498],\n",
       " 'beginning': [463, 521],\n",
       " 'moments': [488, 595],\n",
       " 'appalling': [75, 13],\n",
       " 'his': [3707, 4326],\n",
       " 'snack': [7, 1],\n",
       " 'score': [284, 419],\n",
       " 'others': [454, 632],\n",
       " 'usual': [292, 384],\n",
       " 'affair': [115, 131],\n",
       " 'major': [313, 291],\n",
       " 'seems': [1177, 953],\n",
       " 'cool': [344, 303],\n",
       " 'phenomena': [9, 5],\n",
       " 'head': [558, 451],\n",
       " 'kind': [918, 807],\n",
       " 'slow': [419, 320],\n",
       " 'certainly': [433, 555],\n",
       " 'music': [764, 964],\n",
       " 'feature': [238, 293],\n",
       " 'course': [732, 933],\n",
       " 'adopted': [19, 26],\n",
       " 'ok': [472, 209],\n",
       " 'victim': [150, 134],\n",
       " 'ummm': [6, 3],\n",
       " 'yawn': [47, 1],\n",
       " 'do': [2818, 2217],\n",
       " 'eventually': [216, 264],\n",
       " 'relief': [92, 81],\n",
       " 'huh': [74, 25],\n",
       " 'priest': [80, 47],\n",
       " 'school': [528, 420],\n",
       " 'via': [54, 69],\n",
       " 'source': [73, 82],\n",
       " 'whole': [1144, 863],\n",
       " 'stairs': [26, 18],\n",
       " 'inferno': [7, 8],\n",
       " 'bringing': [66, 93],\n",
       " 'suggesting': [13, 17],\n",
       " 'inappropriately': [11, 3],\n",
       " 'part': [1187, 1231],\n",
       " 'vs': [63, 81],\n",
       " 'decided': [296, 201],\n",
       " 'fiction': [121, 187],\n",
       " 'suicide': [98, 117],\n",
       " 'old': [1278, 1321],\n",
       " 'out': [4120, 3840],\n",
       " 'must': [992, 1124],\n",
       " 'notice': [134, 130],\n",
       " 'kinda': [117, 78],\n",
       " 'deaths': [90, 57],\n",
       " 'sense': [844, 655],\n",
       " 'unfolded': [3, 15],\n",
       " 'headed': [60, 62],\n",
       " 'short': [545, 604],\n",
       " 'distressing': [5, 5],\n",
       " 'age': [271, 444],\n",
       " 'sequel': [295, 191],\n",
       " 'were': [2790, 2272],\n",
       " 'cult': [167, 128],\n",
       " 'there': [4478, 3711],\n",
       " 'successful': [148, 214],\n",
       " 'cheek': [38, 41],\n",
       " 'off': [1987, 1514],\n",
       " 'demonic': [29, 10],\n",
       " 'don': [2859, 2002],\n",
       " 'born': [92, 159],\n",
       " 'see': [2918, 3204],\n",
       " 'dies': [129, 115],\n",
       " 'bottom': [207, 97],\n",
       " 'distressed': [2, 10],\n",
       " 'olds': [32, 7],\n",
       " 'clich': [386, 135],\n",
       " 'where': [1783, 1766],\n",
       " 'provides': [56, 178],\n",
       " 'reactionary': [9, 5],\n",
       " 'start': [634, 514],\n",
       " 'protect': [44, 77],\n",
       " 'after': [2204, 2155],\n",
       " 'wrong': [716, 464],\n",
       " 'acted': [216, 245],\n",
       " 'wtf': [35, 3],\n",
       " 'blanche': [5, 2],\n",
       " 'revisit': [9, 12],\n",
       " 'comical': [66, 52],\n",
       " 'trilogy': [44, 90],\n",
       " 'had': [3077, 2561],\n",
       " 'still': [1410, 1910],\n",
       " 'seconds': [186, 59],\n",
       " 'started': [376, 283],\n",
       " 'girls': [335, 267],\n",
       " 'prove': [100, 89],\n",
       " 'lacks': [186, 70],\n",
       " '8': [161, 437],\n",
       " 'acting': [2490, 1571],\n",
       " 'convoluted': [59, 28],\n",
       " 'matched': [24, 48],\n",
       " 'shoulders': [20, 41],\n",
       " 'lacking': [127, 62],\n",
       " 'any': [2545, 1765],\n",
       " 'bite': [41, 27],\n",
       " 'made': [2566, 2233],\n",
       " 'sensical': [5, 0],\n",
       " 'discover': [75, 117],\n",
       " 'looks': [949, 560],\n",
       " 'lived': [103, 160],\n",
       " 'snakes': [25, 5],\n",
       " 'architecture': [7, 14],\n",
       " 'jnr': [4, 5],\n",
       " 'example': [504, 416],\n",
       " 'surprised': [221, 348],\n",
       " 'nuns': [16, 8],\n",
       " 'thin': [161, 83],\n",
       " 'medical': [52, 38],\n",
       " 'preaching': [18, 18],\n",
       " 'decapitation': [13, 0],\n",
       " 'many': [1665, 2137],\n",
       " 'groovy': [12, 11],\n",
       " 'demolition': [8, 3],\n",
       " 'adopt': [8, 12],\n",
       " 'itself': [531, 503],\n",
       " 'heavily': [60, 68],\n",
       " 'zealot': [5, 1],\n",
       " 'reviewed': [21, 20],\n",
       " 'stare': [33, 14],\n",
       " 'watching': [1633, 1250],\n",
       " 'therefore': [117, 110],\n",
       " 'doing': [642, 456],\n",
       " 'revealing': [35, 51],\n",
       " 'troubled': [23, 84],\n",
       " 'clutching': [5, 6],\n",
       " 'unintended': [10, 0],\n",
       " 'contemplating': [10, 12],\n",
       " 'fully': [115, 171],\n",
       " 'laugh': [532, 401],\n",
       " 'yeah': [240, 91],\n",
       " 'could': [2602, 1917],\n",
       " 'thorn': [8, 7],\n",
       " 'concerned': [96, 90],\n",
       " 'full': [529, 639],\n",
       " 'crossing': [17, 31],\n",
       " 'been': [2752, 2249],\n",
       " 'ridiculous': [523, 128],\n",
       " 'lot': [1179, 1306],\n",
       " 'reaction': [77, 94],\n",
       " 'obviously': [474, 306],\n",
       " 'bitten': [37, 13],\n",
       " 'favorably': [4, 4],\n",
       " 'someone': [927, 563],\n",
       " 'am': [891, 811],\n",
       " 'crazy': [214, 207],\n",
       " 'another': [1416, 1291],\n",
       " 'may': [864, 1160],\n",
       " 'religious': [98, 77],\n",
       " 'meet': [186, 274],\n",
       " 'gun': [196, 133],\n",
       " 'respect': [155, 186],\n",
       " 'often': [422, 617],\n",
       " 'collapses': [9, 12],\n",
       " 'third': [244, 265],\n",
       " 'wraps': [7, 12],\n",
       " 'said': [805, 642],\n",
       " 'scene': [1468, 1415],\n",
       " 'executed': [85, 87],\n",
       " 'both': [742, 1300],\n",
       " 'pit': [21, 35],\n",
       " 'omen': [26, 8],\n",
       " 'daughter': [308, 335],\n",
       " 'damien': [7, 4],\n",
       " 'goes': [823, 801],\n",
       " 'laughed': [134, 129],\n",
       " 'happening': [148, 120],\n",
       " 'best': [1306, 2374],\n",
       " 'cries': [25, 16],\n",
       " 'somehow': [298, 208],\n",
       " 'suspense': [230, 249],\n",
       " 'glory': [46, 58],\n",
       " 'psychic': [39, 20],\n",
       " 'parking': [25, 12],\n",
       " 'exchanging': [4, 7],\n",
       " 'street': [187, 241],\n",
       " 'strange': [289, 312],\n",
       " 'nanny': [11, 9],\n",
       " 'finding': [99, 162],\n",
       " 'musical': [206, 315],\n",
       " 'ball': [82, 95],\n",
       " 'drama': [335, 538],\n",
       " 'entire': [567, 409],\n",
       " 'too': [2231, 2046],\n",
       " 'detective': [99, 158],\n",
       " 'monotonous': [28, 3],\n",
       " 'party': [162, 189],\n",
       " 'ridiculousness': [10, 3],\n",
       " 'handling': [29, 27],\n",
       " 'wasn': [930, 554],\n",
       " 'freak': [56, 22],\n",
       " 'suggested': [26, 36],\n",
       " 'attempt': [484, 218],\n",
       " 'redeeming': [215, 24],\n",
       " 'provide': [101, 107],\n",
       " 'stares': [21, 10],\n",
       " 'year': [647, 794],\n",
       " 'while': [1412, 1676],\n",
       " 'grown': [74, 84],\n",
       " 'me': [2962, 2593],\n",
       " 'additionally': [24, 14],\n",
       " 'only': [3510, 2809],\n",
       " 'insert': [23, 9],\n",
       " 'motion': [158, 150],\n",
       " 'tv': [813, 770],\n",
       " 'everyone': [647, 779],\n",
       " 'degree': [76, 75],\n",
       " 'hardly': [265, 166],\n",
       " 'centering': [2, 9],\n",
       " 'we': [2212, 2289],\n",
       " 'when': [3268, 3520],\n",
       " 'over': [1862, 1730],\n",
       " 'nun': [20, 13],\n",
       " 'ensuing': [8, 12],\n",
       " 'alarmed': [3, 4],\n",
       " 'annoying': [527, 142],\n",
       " 'himself': [600, 727],\n",
       " 'several': [418, 521],\n",
       " 'becomes': [408, 476],\n",
       " 'distracting': [46, 27],\n",
       " 'didn': [1580, 1048],\n",
       " 'god': [425, 243],\n",
       " 'fair': [176, 150],\n",
       " 'whether': [281, 311],\n",
       " 'oh': [695, 259],\n",
       " 'resulting': [36, 32],\n",
       " 'fourth': [46, 68],\n",
       " 'expect': [413, 402],\n",
       " 'lack': [456, 247],\n",
       " 'just': [4473, 3466],\n",
       " 'chest': [45, 16],\n",
       " 'investigator': [18, 17],\n",
       " 'fill': [107, 50],\n",
       " 'expected': [263, 223],\n",
       " 'speed': [69, 71],\n",
       " 'described': [84, 85],\n",
       " 'accident': [112, 110],\n",
       " 'pointless': [318, 32],\n",
       " 'inappropriate': [50, 13],\n",
       " 'obvious': [458, 270],\n",
       " 'car': [378, 318],\n",
       " 'quite': [1018, 1271],\n",
       " 'alternative': [23, 31],\n",
       " 'down': [1226, 1114],\n",
       " 'exposing': [15, 12],\n",
       " 'encounter': [52, 69],\n",
       " 'straight': [324, 231],\n",
       " 'mysterious': [134, 157],\n",
       " 'believe': [932, 728],\n",
       " 'skills': [87, 96],\n",
       " 'hoping': [210, 86],\n",
       " 'ambitious': [37, 54],\n",
       " 'identities': [12, 15],\n",
       " 'matter': [364, 410],\n",
       " 'appropriate': [57, 91],\n",
       " 'arts': [87, 90],\n",
       " 'battle': [141, 210],\n",
       " 'violence': [319, 359],\n",
       " 'alone': [341, 358],\n",
       " 'high': [679, 673],\n",
       " 'trip': [144, 181],\n",
       " 'ancient': [78, 80],\n",
       " 'home': [518, 614],\n",
       " 'upon': [253, 331],\n",
       " 'seem': [767, 673],\n",
       " 'befriending': [2, 4],\n",
       " 'kissing': [34, 27],\n",
       " 'cannon': [22, 30],\n",
       " 'away': [951, 860],\n",
       " 'ten': [318, 249],\n",
       " 'lit': [47, 28],\n",
       " 'lesbianism': [11, 10],\n",
       " 'taken': [343, 362],\n",
       " 'laughable': [274, 33],\n",
       " 'cruelty': [24, 27],\n",
       " 'restore': [8, 11],\n",
       " 'low': [779, 386],\n",
       " 'shannon': [15, 11],\n",
       " 'twenty': [102, 106],\n",
       " 'jason': [98, 102],\n",
       " 'refrain': [13, 5],\n",
       " 'captain': [74, 90],\n",
       " 'ago': [293, 438],\n",
       " 'training': [59, 83],\n",
       " 'ward': [21, 37],\n",
       " 'demon': [61, 35],\n",
       " 'never': [1843, 1904],\n",
       " 'moment': [325, 400],\n",
       " 'candy': [92, 74],\n",
       " 'flicks': [160, 100],\n",
       " 'tree': [65, 40],\n",
       " 'led': [100, 137],\n",
       " 'toying': [2, 4],\n",
       " 'written': [537, 531],\n",
       " 'remember': [477, 622],\n",
       " 'pleasure': [79, 137],\n",
       " 'again': [1140, 1285],\n",
       " 'flat': [316, 114],\n",
       " 'chicken': [29, 22],\n",
       " 'vanessa': [22, 13],\n",
       " 'fianc': [39, 46],\n",
       " 'fad': [6, 2],\n",
       " 'dark': [338, 494],\n",
       " 'develops': [29, 68],\n",
       " 'trouble': [189, 181],\n",
       " 'rest': [709, 536],\n",
       " 'buddies': [40, 33],\n",
       " 'case': [519, 467],\n",
       " 'clad': [24, 19],\n",
       " 'portal': [6, 0],\n",
       " 'love': [1205, 2146],\n",
       " 'favorable': [12, 4],\n",
       " 'rating': [351, 263],\n",
       " 'trained': [22, 47],\n",
       " 'spend': [220, 146],\n",
       " 'eye': [265, 311],\n",
       " 'brigitte': [3, 13],\n",
       " 'feelings': [73, 189],\n",
       " 'marlene': [4, 12],\n",
       " 'dressed': [105, 79],\n",
       " 'falls': [336, 266],\n",
       " 'silly': [402, 186],\n",
       " 'entertainment': [277, 322],\n",
       " 'unlikely': [74, 88],\n",
       " 'though': [1263, 1449],\n",
       " 'wishes': [50, 63],\n",
       " 'steer': [33, 9],\n",
       " 'until': [564, 631],\n",
       " 'vanished': [10, 8],\n",
       " 'darkly': [10, 22],\n",
       " 'heap': [22, 9],\n",
       " 'him': [1757, 2096],\n",
       " 'known': [319, 415],\n",
       " 'monsters': [120, 64],\n",
       " 'mostly': [325, 329],\n",
       " 'snapping': [5, 3],\n",
       " 'knowledge': [92, 101],\n",
       " 'came': [523, 607],\n",
       " 'fun': [626, 981],\n",
       " 'containing': [19, 24],\n",
       " 'now': [1356, 1454],\n",
       " 'young': [749, 1267],\n",
       " 'cohorts': [12, 7],\n",
       " 'warrior': [37, 28],\n",
       " 'fodder': [32, 5],\n",
       " 'kidnapped': [50, 44],\n",
       " 'budget': [733, 397],\n",
       " 'action': [847, 943],\n",
       " 'fool': [66, 54],\n",
       " 'beast': [54, 40],\n",
       " 'lesbian': [82, 38],\n",
       " 'gaze': [9, 10],\n",
       " 'bi': [9, 5],\n",
       " 'scantily': [15, 8],\n",
       " 'sound': [446, 378],\n",
       " 'their': [2576, 2777],\n",
       " 'fire': [203, 182],\n",
       " 'co': [207, 206],\n",
       " 'please': [463, 245],\n",
       " 'body': [355, 273],\n",
       " 'spice': [22, 17],\n",
       " 'aims': [14, 11],\n",
       " 'adults': [107, 149],\n",
       " 'set': [748, 822],\n",
       " 'quivering': [2, 7],\n",
       " 'anyway': [449, 351],\n",
       " 'toned': [19, 22],\n",
       " 'spoken': [58, 69],\n",
       " 'help': [593, 654],\n",
       " 'sidelines': [6, 2],\n",
       " 'confined': [11, 21],\n",
       " 'likable': [102, 158],\n",
       " 'needed': [278, 197],\n",
       " 'hard': [914, 853],\n",
       " 'somethings': [19, 12],\n",
       " 'free': [290, 204],\n",
       " 'christian': [130, 68],\n",
       " 'less': [691, 629],\n",
       " 'other': [2444, 2654],\n",
       " 'material': [305, 238],\n",
       " 'hot': [238, 189],\n",
       " 'group': [353, 290],\n",
       " 'decipher': [8, 4],\n",
       " 'think': [2071, 2030],\n",
       " 'text': [48, 37],\n",
       " 'opened': [58, 58],\n",
       " 'once': [716, 876],\n",
       " 'pass': [189, 113],\n",
       " 'marketed': [12, 5],\n",
       " 'enthusiastic': [20, 27],\n",
       " 'having': [827, 833],\n",
       " 'passing': [56, 74],\n",
       " 'solely': [47, 24],\n",
       " 'wilderness': [15, 22],\n",
       " 'conan': [22, 23],\n",
       " 'lost': [478, 510],\n",
       " 'getting': [593, 492],\n",
       " 'ricky': [8, 20],\n",
       " 'babe': [28, 34],\n",
       " 'naive': [74, 91],\n",
       " 'demons': [39, 52],\n",
       " 'probably': [935, 923],\n",
       " 'name': [599, 467],\n",
       " 'courageous': [9, 18],\n",
       " 'appears': [322, 260],\n",
       " 'hiding': [45, 59],\n",
       " 'athletic': [7, 19],\n",
       " 'alter': [26, 20],\n",
       " 'woods': [131, 88],\n",
       " 'lends': [8, 33],\n",
       " 'nicely': [66, 140],\n",
       " 'using': [297, 259],\n",
       " 'restraining': [8, 1],\n",
       " 'closing': [66, 69],\n",
       " 'flame': [15, 15],\n",
       " 'attempts': [240, 153],\n",
       " 'practitioner': [6, 2],\n",
       " 'portion': [36, 35],\n",
       " 'humor': [353, 480],\n",
       " 'these': [1576, 1549],\n",
       " 'loopy': [4, 7],\n",
       " 'camp': [135, 126],\n",
       " 'blackness': [3, 2],\n",
       " 'most': [2224, 2638],\n",
       " 'superficial': [48, 31],\n",
       " 'gorgeous': [75, 198],\n",
       " 'female': [347, 254],\n",
       " 'wrestling': [42, 17],\n",
       " 'serious': [320, 330],\n",
       " 'starring': [144, 214],\n",
       " 'sexual': [200, 229],\n",
       " 'hero': [296, 308],\n",
       " 'idea': [839, 485],\n",
       " 'book': [508, 561],\n",
       " 'goofy': [63, 49],\n",
       " 'presented': [133, 155],\n",
       " 'ex': [147, 160],\n",
       " 'everything': [776, 741],\n",
       " 'lighted': [14, 3],\n",
       " 'jasmine': [5, 3],\n",
       " 'guess': [585, 297],\n",
       " 'opening': [336, 307],\n",
       " 'fondling': [7, 2],\n",
       " 'tame': [38, 31],\n",
       " 'reasons': [211, 214],\n",
       " 'purely': [70, 45],\n",
       " 'nice': [557, 739],\n",
       " 'nudity': [267, 117],\n",
       " 'night': [651, 655],\n",
       " 'rekindle': [4, 6],\n",
       " 'james': [214, 370],\n",
       " 'against': [430, 521],\n",
       " 'years': [1093, 1659],\n",
       " 'three': [657, 691],\n",
       " 'spoofing': [8, 8],\n",
       " 'might': [1056, 775],\n",
       " 'revealed': [78, 97],\n",
       " 'preposterous': [38, 13],\n",
       " 'women': [539, 448],\n",
       " 'witches': [19, 24],\n",
       " 'haley': [3, 11],\n",
       " 'ego': [53, 35],\n",
       " 'scrutiny': [10, 6],\n",
       " 'setting': [201, 270],\n",
       " 'towards': [190, 244],\n",
       " 'running': [389, 278],\n",
       " 'almost': [971, 985],\n",
       " 'kingsley': [15, 9],\n",
       " 'stands': [103, 177],\n",
       " 'things': [1102, 1138],\n",
       " 'showing': [249, 308],\n",
       " 'summer': [91, 126],\n",
       " 'contains': [133, 169],\n",
       " 'join': [54, 67],\n",
       " 'mighty': [30, 26],\n",
       " 'boys': [161, 200],\n",
       " 'explosions': [35, 41],\n",
       " 'found': [835, 849],\n",
       " 'agents': [32, 27],\n",
       " 'garnered': [9, 13],\n",
       " 'enjoy': [435, 760],\n",
       " 'bother': [233, 53],\n",
       " 'judging': [50, 28],\n",
       " 'audiences': [135, 183],\n",
       " 'along': [530, 680],\n",
       " 'toward': [89, 102],\n",
       " 'herzog': [8, 4],\n",
       " 'jersey': [14, 26],\n",
       " 'praise': [61, 67],\n",
       " 'maybe': [888, 626],\n",
       " 'whereas': [61, 52],\n",
       " 'honesty': [27, 44],\n",
       " 'dining': [10, 6],\n",
       " 'seriously': [478, 227],\n",
       " 'channels': [40, 31],\n",
       " 'get': [2724, 2403],\n",
       " 'clothing': [40, 35],\n",
       " 'comes': [777, 834],\n",
       " 'long': [1100, 1066],\n",
       " 'simply': [726, 549],\n",
       " 'nicolas': [15, 25],\n",
       " 'mystery': [252, 288],\n",
       " 'pay': [242, 163],\n",
       " 'shock': [139, 118],\n",
       " 'wondering': [155, 105],\n",
       " 'shoved': [21, 10],\n",
       " 'tripe': [55, 4],\n",
       " 'gee': [22, 5],\n",
       " 'engaged': [34, 45],\n",
       " 'instead': [985, 483],\n",
       " 'wondered': [46, 49],\n",
       " 'finished': [126, 107],\n",
       " 'jon': [45, 66],\n",
       " 'paranoid': [18, 23],\n",
       " 'view': [264, 398],\n",
       " 'fries': [3, 2],\n",
       " 'among': [208, 333],\n",
       " 'voight': [9, 46],\n",
       " 'know': [1863, 1707],\n",
       " 'writer': [413, 344],\n",
       " 'cage': [54, 64],\n",
       " 'ignorant': [48, 20],\n",
       " 'caught': [155, 236],\n",
       " 'absorbing': [9, 33],\n",
       " 'lines': [591, 417],\n",
       " 'insulting': [69, 13],\n",
       " 'actual': [308, 255],\n",
       " 'treasure': [33, 94],\n",
       " 'laden': [23, 17],\n",
       " 'jargon': [7, 1],\n",
       " 'saying': [436, 215],\n",
       " 'fathers': [20, 34],\n",
       " 'critical': [61, 74],\n",
       " 'bothered': [96, 28],\n",
       " 'succeeded': [42, 32],\n",
       " 'mention': [348, 241],\n",
       " 'perhaps': [520, 572],\n",
       " 'heaping': [4, 3],\n",
       " 'france': [50, 94],\n",
       " 'suspension': [37, 18],\n",
       " 'audience': [703, 666],\n",
       " 'disbelief': [87, 47],\n",
       " 'intended': [165, 117],\n",
       " 'threw': [64, 23],\n",
       " 'why': [1788, 1118],\n",
       " 'british': [216, 291],\n",
       " 'true': [545, 925],\n",
       " 'explain': [187, 135],\n",
       " 'actually': [1497, 1108],\n",
       " 'hid': [8, 4],\n",
       " 'founding': [4, 6],\n",
       " 'cum': [8, 8],\n",
       " 'goonies': [4, 3],\n",
       " 'clearly': [340, 272],\n",
       " 'gates': [14, 14],\n",
       " 'asks': [101, 124],\n",
       " 'adult': [129, 198],\n",
       " 'breakneck': [4, 1],\n",
       " 'big': [1027, 1088],\n",
       " 'previews': [24, 22],\n",
       " 'willfully': [4, 3],\n",
       " 'conspiracy': [44, 33],\n",
       " 'mac': [14, 9],\n",
       " 'wonderment': [2, 3],\n",
       " 'appeal': [170, 147],\n",
       " 'werner': [8, 10],\n",
       " 'outside': [197, 209],\n",
       " 'belief': [75, 62],\n",
       " 'ended': [233, 166],\n",
       " 'myself': [453, 329],\n",
       " 'philadelphia': [12, 15],\n",
       " 'per': [59, 50],\n",
       " 'end': [1715, 1636],\n",
       " 'napoleon': [14, 7],\n",
       " 'resisting': [2, 3],\n",
       " 'forget': [251, 246],\n",
       " 'keitel': [20, 5],\n",
       " 'chases': [56, 50],\n",
       " 'hollywood': [494, 636],\n",
       " 'plummer': [13, 7],\n",
       " 'sci': [191, 186],\n",
       " 'talking': [353, 268],\n",
       " 'okay': [309, 155],\n",
       " 'watched': [761, 723],\n",
       " 'templar': [4, 1],\n",
       " 'brought': [200, 336],\n",
       " 'fi': [194, 188],\n",
       " 'wow': [174, 100],\n",
       " 'render': [14, 12],\n",
       " 'pre': [84, 128],\n",
       " 'teen': [124, 93],\n",
       " 'hands': [224, 234],\n",
       " 'ever': [1883, 1699],\n",
       " 'pastiche': [9, 7],\n",
       " 'mean': [721, 375],\n",
       " 'switch': [41, 25],\n",
       " 'l': [127, 120],\n",
       " 'quickly': [224, 227],\n",
       " 'knights': [12, 11],\n",
       " 'evoke': [19, 12],\n",
       " 'waiting': [205, 194],\n",
       " 'targeted': [20, 17],\n",
       " 'whiz': [8, 3],\n",
       " 'blew': [36, 48],\n",
       " 'm': [1757, 1179],\n",
       " 'll': [955, 846],\n",
       " 'sort': [532, 419],\n",
       " 'theory': [62, 53],\n",
       " 'surprise': [202, 290],\n",
       " 'items': [23, 28],\n",
       " 'national': [79, 82],\n",
       " 'fine': [320, 539],\n",
       " 'interesting': [1068, 939],\n",
       " 'premise': [328, 154],\n",
       " 'stood': [34, 62],\n",
       " 'during': [647, 701],\n",
       " 'keep': [530, 571],\n",
       " 'harvey': [40, 29],\n",
       " 'screenwriter': [70, 45],\n",
       " 'cinema': [351, 521],\n",
       " 'lay': [41, 33],\n",
       " 'office': [156, 205],\n",
       " 'dean': [52, 55],\n",
       " 'submit': [13, 13],\n",
       " 'imagine': [294, 245],\n",
       " 'rock': [198, 247],\n",
       " 'wonder': [437, 279],\n",
       " 'let': [887, 618],\n",
       " 'heir': [9, 12],\n",
       " 'delay': [8, 4],\n",
       " 'survive': [76, 98],\n",
       " 'superior': [83, 141],\n",
       " 'giants': [19, 19],\n",
       " 'disrespect': [12, 7],\n",
       " 'read': [654, 547],\n",
       " 'perform': [48, 59],\n",
       " 'bankable': [5, 4],\n",
       " 'least': [1293, 745],\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVocab_Directory_Full = Vocab_buider(train_Data)\n",
    "trainVocab_Directory = verify_occur_threshold(trainVocab_Directory_Full ,5)\n",
    "trainVocab_Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.Probability of the occurrence\n",
    "\n",
    "\n",
    "def find_total_label_list_ofdata(data):\n",
    "    result_list = [0, 0, len(data)]\n",
    "    \n",
    "    for single_data in data:\n",
    "        result_list[single_data[1]] += 1\n",
    "    \n",
    "    return result_list\n",
    "    \n",
    "\n",
    "def Probability_of_Occurance(word, vocab_Directory, total_Count):\n",
    "    if word not in vocab_Directory:\n",
    "        return 0\n",
    "    else:\n",
    "        return ((vocab_Directory[word][0] + vocab_Directory[word][1])/total_Count)\n",
    "\n",
    "# Conditional probability based on the sentiment\n",
    "def conditional_Probability_of_word(word, vocab_Directory, label):\n",
    "    temp_list = find_total_label_list_ofdata(train_Data)\n",
    "    \n",
    "    if word not in vocab_Directory:\n",
    "        return 0\n",
    "    elif int(label) == 0:\n",
    "        return (vocab_Directory[word][0]/temp_list[0])\n",
    "    elif int(label) == 1:\n",
    "        return (vocab_Directory[word][1]/temp_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"the\"] =  0.9912533333333333\n",
      "P[\"the\"|Negative] =  0.9925229651783807\n",
      "P[\"the\"|Positive] =  0.989987217724755\n"
     ]
    }
   ],
   "source": [
    "print('P[\"the\"] = ', Probability_of_Occurance('the', trainVocab_Directory, len(train_Data)))\n",
    "print('P[\"the\"|Negative] = ', conditional_Probability_of_word('the', trainVocab_Directory, 0))\n",
    "print('P[\"the\"|Positive] = ', conditional_Probability_of_word('the', trainVocab_Directory, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d. Calculate accuracy using dev dataset \n",
    "\n",
    "\n",
    "def make_prediction(rev, vocab, n_p_list, lambda_threshold, length_Of_Data):\n",
    "    List_probability = list()\n",
    "    \n",
    "    for l in [0, 1]:\n",
    "        single_prob = log(n_p_list[l]/length_Of_Data)\n",
    "        \n",
    "        for w in rev[0]:\n",
    "            if w not in vocab:\n",
    "                continue\n",
    "            if lambda_threshold == 0 and vocab[w][l] == 0:\n",
    "                single_prob = 0\n",
    "                break\n",
    "                \n",
    "            single_prob += log((vocab[w][l] + lambda_threshold) / (vocab[w][0] + vocab[w][1] + lambda_threshold))\n",
    "        \n",
    "        List_probability.append(single_prob)\n",
    "        \n",
    "    return 0 if List_probability[0] > List_probability[1] else 1\n",
    "\n",
    "def part_data_to_kfolds(empty_list, data, k):\n",
    "    fold_Length = len(data)//k\n",
    "    \n",
    "    for i in range(k):\n",
    "        shuffle(data)\n",
    "        single_Fold = data[:fold_Length]\n",
    "        data = data[fold_Length:]\n",
    "        empty_list.append(single_Fold)\n",
    "        \n",
    "\n",
    "def cal_data_accu_for_kfolds(data, lambda_threshold, k, Occurance_count):\n",
    "    List_accuracy = list()\n",
    "    List_fold = list()\n",
    "    \n",
    "    Equivalent_data = list(data)\n",
    "    \n",
    "    part_data_to_kfolds(List_fold, Equivalent_data, k)\n",
    "    \n",
    "    #print(List_fold)\n",
    "    \n",
    "    for fold in List_fold:\n",
    "        train_List_fold = list(List_fold)\n",
    "        list(List_fold).remove(fold)\n",
    "        train_List_fold = sum(train_List_fold, [])\n",
    "        test_List_fold = fold\n",
    "        \n",
    "        vocab = verify_occur_threshold(Vocab_buider(train_List_fold), Occurance_count)\n",
    "        \n",
    "        total_label_list = find_total_label_list_ofdata(train_List_fold)\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for rev in test_List_fold:\n",
    "            if make_prediction(rev, vocab, total_label_list, lambda_threshold, len(train_List_fold)) == rev[1]:\n",
    "                counter += 1\n",
    "        \n",
    "        List_accuracy.append(counter / len(test_List_fold))\n",
    "        \n",
    "    return List_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5-fold:  [0.5, 0.5224, 0.5248, 0.4792, 0.5104]\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "print('Accuracy for 5-fold: ', cal_data_accu_for_kfolds(dev_Data, 0, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. calculate accuracy and find top 10 negative and positive words from dataset.\n",
    "\n",
    "def cal_accuracy_function(train_dataset, test_dataset, lambda_threshold, Occurance_count):\n",
    "    vocab = Vocab_buider(train_dataset)\n",
    "    vocab = verify_occur_threshold(vocab, Occurance_count)\n",
    "    \n",
    "    total_label_list = find_total_label_list_ofdata(train_dataset)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for r in test_dataset:\n",
    "        if make_prediction(r, vocab, total_label_list, lambda_threshold, len(train_dataset)) == r[1]:\n",
    "            counter += 1\n",
    "            \n",
    "    return (counter / len(test_dataset))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without smoothing:  0.49152\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy without smoothing: ', cal_accuracy_function(train_Data, dev_Data, 0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with laplace estimate:  0.4912\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy with laplace estimate: ', cal_accuracy_function(train_Data, dev_Data, 1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_words(data, label, lambda_threshold, Occurance_count):\n",
    "    vocab = Vocab_buider(data)\n",
    "    vocab = verify_occur_threshold(vocab, Occurance_count)\n",
    "    \n",
    "    words = list()\n",
    "    \n",
    "    for word in list(vocab.keys()):\n",
    "        temp = (vocab[word][label] + lambda_threshold) / (vocab[word][0] + lambda_threshold + vocab[word][1] + lambda_threshold)\n",
    "        words.append([word, temp])\n",
    "        \n",
    "    words = numpy.array(words)\n",
    "    words = words[numpy.lexsort(words.T)]\n",
    "    \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = get_top_10_words(dev_Data, 0, 1, 5)[:10]\n",
    "positive_words = get_top_10_words(dev_Data, 1, 1, 5)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['simplicity' '0.043478260869565216']\n",
      " ['walsh' '0.05555555555555555']\n",
      " ['technicolor' '0.0625']\n",
      " ['nuanced' '0.06666666666666667']\n",
      " ['1936' '0.07142857142857142']\n",
      " ['absorbing' '0.07142857142857142']\n",
      " ['excellently' '0.07142857142857142']\n",
      " ['raoul' '0.07142857142857142']\n",
      " ['conductor' '0.07692307692307693']\n",
      " ['heartwarming' '0.07692307692307693']]\n"
     ]
    }
   ],
   "source": [
    "print(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['drivel' '0.03225806451612903']\n",
      " ['incoherent' '0.034482758620689655']\n",
      " ['dreck' '0.03571428571428571']\n",
      " ['stinker' '0.05']\n",
      " ['nope' '0.058823529411764705']\n",
      " ['semblance' '0.058823529411764705']\n",
      " ['boll' '0.0625']\n",
      " ['incompetent' '0.0625']\n",
      " ['mercifully' '0.0625']\n",
      " ['redeeming' '0.0641025641025641']]\n"
     ]
    }
   ],
   "source": [
    "print(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f. Using the test dataset\n",
    "\n",
    "end_accuracy = cal_accuracy_function(train_Data, test_Data, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
